{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6470ae2ce864905815a77f80903eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py as pm\n",
    "from sqlalchemy import create_engine\n",
    "from resources__ import variants\n",
    "import datetime\n",
    "import plotly.express as plx\n",
    "\n",
    "#db_connection\n",
    "db_provider = \"postgresql://\"\n",
    "user = \"ubuntu1\"\n",
    "password =\"3004222950a\"\n",
    "address  = \"20.226.14.116:5432/postgres\"\n",
    "engine = create_engine(db_provider + user + \":\" + password  + '@'+ address)\n",
    "\n",
    "\n",
    "# Read eventlog\n",
    "event_log = pm.read_xes('Hospital Billing - Event Log.xes.gz')\n",
    "event_log_df = pm.convert_to_dataframe(event_log)\n",
    "event_log_df['time:timestamp'] = pd.to_datetime(event_log_df['time:timestamp'],utc=True)\n",
    "#event_log_df.to_sql('event_log',con = engine,schema='billing',if_exists = 'replace' )\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overveiw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Dataframe with traces\n",
    "df_variants = variants.get_variants_df(event_log)\n",
    "df_variants['info'] = df_variants['info'].astype(str)\n",
    "#  df_variants.to_sql(name=\"variants_total_df\",con=engine,if_exists='replace',index =False,schema=\"billing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview Information   --------------- { Cses, Events, Activities, Variants, States, Period }\n",
    "years = event_log_df['time:timestamp'].dt.year.unique().tolist()\n",
    "dataframes = []\n",
    "__dataframes = []\n",
    "for year in years:\n",
    "    traces_contained = pm.filter_time_range(event_log,dt1=datetime.datetime(year-1,12,31),dt2=datetime.datetime(year,12,31),mode='traces_contained')\n",
    "    df_traces_contained = pm.convert_to_dataframe(traces_contained)\n",
    "    variants_trace = pm.get_variants_as_tuples(traces_contained)\n",
    "    var_ = []\n",
    "    data_ = []\n",
    "    for var,dat in variants_trace.items():\n",
    "        var_.append(var)\n",
    "        data_.append(dat)\n",
    "    df_g = pd.DataFrame({'var':var_,'dat':data_})\n",
    "    xc = ['variant_' + str(h) for h in np.arange(len(df_g))]\n",
    "    df_g['v_name'] = xc\n",
    "    __dataframes.append(df_g)\n",
    "    events_ = [len(df_traces_contained)]\n",
    "    total_variants = [len(df_g)]\n",
    "    activities = [len(df_traces_contained['concept:name'].unique())]\n",
    "    cases = [len(df_traces_contained['case:concept:name'].unique())]\n",
    "    states = [len(df_traces_contained['state'].unique())] # ----------------------------------------------------------------This particular event log has states\n",
    "    df_final = pd.DataFrame({\n",
    "        'Cases':cases,\n",
    "        'Events':events_,\n",
    "        'Activities':activities,\n",
    "        'Variants': total_variants,\n",
    "        'States': states, # ----------------------------------------------------------------This particular event log has states\n",
    "        'year': [year]\n",
    "    })\n",
    "    dataframes.append(df_final)\n",
    "\n",
    "events_ = [len(event_log_df)]\n",
    "total_variants = [len(df_variants)]\n",
    "activities = [len(event_log_df['concept:name'].unique())]\n",
    "cases = [len(event_log_df['case:concept:name'].unique())]\n",
    "states = [len(event_log_df['state'].unique())] # ----------------------------------------------------------------This particular event log has states\n",
    "df_final_ = pd.DataFrame({\n",
    "    'Cases':cases,\n",
    "    'Events':events_,\n",
    "    'Activities':activities,\n",
    "    'Variants': total_variants,\n",
    "    'States': states, # ----------------------------------------------------------------This particular event log has states\n",
    "    'year': ['total']\n",
    "})\n",
    "\n",
    "years_details_df = pd.concat(dataframes)\n",
    "total_df_details = pd.concat([years_details_df,df_final_])\n",
    "total_df_details.to_sql(name='overview_details',con=engine,schema='billing',if_exists=\"replace\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month and number of activities\n",
    "month = event_log_df[['time:timestamp','case:concept:name']]\n",
    "month['month_year'] = month['time:timestamp'].dt.to_period('M')\n",
    "month_ = month.groupby('month_year')['case:concept:name'].count().to_frame().reset_index()\n",
    "month_['month_year'] =  month_['month_year'].astype(str)\n",
    "month_['month_year'] = pd.to_datetime(month_['month_year'])\n",
    "month_.to_sql(name='count_month',con=engine, schema='billing',if_exists='replace',index =False)\n",
    "\n",
    "# Events_per Case\n",
    "events_per_case_df = event_log_df.groupby(['case:concept:name'])['time:timestamp'].count().to_frame().reset_index()\n",
    "events_per_case_df['t'] = 'a'\n",
    "events_per_case_df = events_per_case_df.groupby('time:timestamp')['t'].count().to_frame().reset_index()\n",
    "events_per_case_df.columns = ['Events per case','Count']\n",
    "events_per_case_df = events_per_case_df.sort_values('Count',ascending=False)\n",
    "#events_per_case_df.to_sql(name='events_per_case_df', con=engine,schema='billing',index=False,if_exists='replace')\n",
    "\n",
    "#Activities per case\n",
    "activities = event_log_df['concept:name'].unique().tolist()\n",
    "numbers = []\n",
    "for activity in activities:\n",
    "    _ = event_log_df[event_log_df['concept:name'] == activity]\n",
    "    numbers.append(len(_['case:concept:name'].unique()))\n",
    "g_df = pd.DataFrame({'activities':activities,'count':numbers})\n",
    "g_df['%'] = g_df['count'] / len(event_log_df['case:concept:name'].unique()) * 100\n",
    "#g_df.to_sql(name='activities per case', con=engine,schema='billing',index=False,if_exists='replace')\n",
    "\n",
    "#Activities per case\n",
    "activities = event_log_df['concept:name'].unique().tolist()\n",
    "numbers = []\n",
    "for activity in activities:\n",
    "    _ = event_log_df[event_log_df['concept:name'] == activity]\n",
    "    numbers.append(len(_['case:concept:name'].unique()))\n",
    "g_df = pd.DataFrame({'activities':activities,'count':numbers})\n",
    "g_df['percentage'] = g_df['count'] / len(event_log_df['case:concept:name'].unique()) * 100\n",
    "g_df.to_sql(name='activities_per_case', con=engine,schema='billing',index=False,if_exists='replace')\n",
    "\n",
    "#Df Canceled\n",
    "df_cancelled = event_log_df.groupby(['case:concept:name','isCancelled'])['time:timestamp'].count().to_frame().reset_index()\n",
    "df_cancelled = df_cancelled.drop_duplicates(subset=['case:concept:name'],keep ='last')\n",
    "df_cancelled =  df_cancelled.groupby('isCancelled')['time:timestamp'].count().to_frame().reset_index()\n",
    "df_cancelled.to_sql(name = 'df_canceled', con=engine,schema =\"billing\",index=False,if_exists='replace')\n",
    "\n",
    "#Df_ Closed\n",
    "df_closed = event_log_df.groupby(['case:concept:name','isClosed'])['time:timestamp'].count().to_frame().reset_index()\n",
    "df_closed = df_closed.drop_duplicates(subset=['case:concept:name'],keep ='last')\n",
    "df_closed =  df_closed.groupby('isClosed')['time:timestamp'].count().to_frame().reset_index()\n",
    "df_closed.to_sql(name = 'df_closed', con=engine,schema =\"billing\",index=False,if_exists='replace')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_level_1():\n",
    "    #Level 1 \n",
    "    level_1 = pm.filter_variants(event_log,[df_variants['trace'].to_list()[0]])\n",
    "    level_1_df = pm.convert_to_dataframe(level_1)\n",
    "    level_1_heunet = pm.discover_heuristics_net(level_1)\n",
    "    pm.view_heuristics_net(level_1_heunet)\n",
    "\n",
    "    # Starting activities & Ending Activities\n",
    "    start_act_1 = pm.get_start_activities(level_1)\n",
    "    key_1 = []\n",
    "    value_1 = []\n",
    "    for k,v in start_act_1.items():\n",
    "        key_1.append(k)\n",
    "        value_1.append(v)\n",
    "    df_start_act_1 = pd.DataFrame({'Activity':key_1,'number_cases':value_1})\n",
    "    df_start_act_1.to_sql(name= 'df_start_act_1', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "    end_act_1 = pm.get_end_activities(level_1)\n",
    "    key_1_e = []\n",
    "    value_1_e = []\n",
    "    for k,v in end_act_1.items():\n",
    "        key_1_e.append(k)\n",
    "        value_1_e.append(v)\n",
    "    df_end_act_1 = pd.DataFrame({'Activity':key_1_e,'number_cases':value_1_e})\n",
    "    df_end_act_1['Percentage'] = df_end_act_1['number_cases'] / len(level_1_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_1.to_sql(name= 'df_end_act_1', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_1 = plx.bar(data_frame=df_end_act_1,y = 'Activity',x = 'Percentage')\n",
    "    #plot_ends_1\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_1 = pm.discover_bpmn_inductive(level_1)\n",
    "    pm.view_bpmn(bpmn_1)\n",
    "\n",
    "    df_variants_level_1 = variants.get_variants_df(level_1)\n",
    "    df_variants_level_1 =  df_variants_level_1[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_1['len_trace'] = [len(x) for x in df_variants_level_1['trace'].to_list() ]\n",
    "    df_variants_level_1.to_sql(name = 'df_variants_level_1', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "    #lenght_variant\n",
    "    len_variance_1 = plx.bar(df_variants_level_1,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_1\n",
    "    ocurrance_1 = plx.bar(df_variants_level_1,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_1\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_1, im_inductive_1, fm_inductive_1 = pm.discover_petri_net_inductive(level_1)\n",
    "    pm.view_petri_net(net_inductive_1, im_inductive_1, fm_inductive_1)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_1, im_alpha_1, fm_alpha_1 = pm.discover_petri_net_alpha(level_1)\n",
    "    pm.view_petri_net(net_alpha_1, im_alpha_1, fm_alpha_1)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_1, im_alphaplus_1, fm_alphaplus_1 = pm.discover_petri_net_alpha_plus(level_1)\n",
    "    pm.view_petri_net(net_alphaplus_1, im_alphaplus_1, fm_alphaplus_1 )\n",
    "\n",
    "#df_start_act_1 = pd.read_sql(sql = \"\"\"SELECT * FROM billing.df_start_act_1\"\"\",con = engine)\n",
    "#df_start_act_1.to_csv('dataframes/df_start_act_1.csv',index = False)\n",
    "\n",
    "#df_end_act_1 = pd.read_sql(sql = \"\"\"SELECT * FROM billing.df_end_act_1\"\"\",con = engine)\n",
    "#df_end_act_1.to_csv('dataframes/df_end_act_1.csv',index = False)\n",
    "\n",
    "#df_variants_level_1 = pd.read_sql(sql = \"\"\"SELECT * FROM billing.df_variants_level_1\"\"\",con = engine)\n",
    "#df_variants_level_1.to_csv('dataframes/df_variants_level_1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_16():\n",
    "    #Level 1 \n",
    "    level_16 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:4])\n",
    "    level_16_df = pm.convert_to_dataframe(level_16)\n",
    "    level_16_heunet = pm.discover_heuristics_net(level_16)\n",
    "    pm.view_heuristics_net(level_16_heunet)\n",
    "\n",
    "    start_act_16 = pm.get_start_activities(level_16)\n",
    "    key_16 = []\n",
    "    value_16 = []\n",
    "    for k,v in start_act_16.items():\n",
    "        key_16.append(k)\n",
    "        value_16.append(v)\n",
    "    df_start_act_16 = pd.DataFrame({'Activity':key_16,'number_cases':value_16})\n",
    "    df_start_act_16.to_sql(name= 'df_start_act_16', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_16 = pm.get_end_activities(level_16)\n",
    "    key_16_e = []\n",
    "    value_16_e = []\n",
    "    for k,v in end_act_16.items():\n",
    "        key_16_e.append(k)\n",
    "        value_16_e.append(v)\n",
    "    df_end_act_16 = pd.DataFrame({'Activity':key_16_e,'number_cases':value_16_e})\n",
    "    df_end_act_16['Percentage'] = df_end_act_16['number_cases'] / len(level_16_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_16.to_sql(name= 'df_end_act_16', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_16 = plx.bar(data_frame=df_end_act_16,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_16\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_16 = pm.discover_bpmn_inductive(level_16)\n",
    "    pm.view_bpmn(bpmn_16)\n",
    "\n",
    "\n",
    "    df_variants_level_16 = variants.get_variants_df(level_16)\n",
    "    df_variants_level_16 =  df_variants_level_16[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_16['len_trace'] = [len(x) for x in df_variants_level_16['trace'].to_list() ]\n",
    "    df_variants_level_16.to_sql(name = 'df_variants_level_16', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "    len_variance_16 = plx.bar(df_variants_level_16,x = 'Variant_Name', y = 'len_trace' )\n",
    "    #len_variance_16\n",
    "    ocurrance_16 = plx.bar(df_variants_level_16,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_16\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_16, im_inductive_16, fm_inductive_16 = pm.discover_petri_net_inductive(level_16)\n",
    "    pm.view_petri_net(net_inductive_16, im_inductive_16, fm_inductive_16)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_16, im_alpha_16, fm_alpha_16 = pm.discover_petri_net_alpha(level_16)\n",
    "    pm.view_petri_net(net_alpha_16, im_alpha_16, fm_alpha_16)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_16, im_alphaplus_16, fm_alphaplus_16 = pm.discover_petri_net_alpha_plus(level_16)\n",
    "    pm.view_petri_net(net_alphaplus_16, im_alphaplus_16, fm_alphaplus_16 )\n",
    "\n",
    "\n",
    "#df_start_act_16 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_16\"\"\", con= engine)\n",
    "#df_end_act_16 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_16\"\"\", con= engine)\n",
    "#df_variants_level_16 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_16\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_16.to_csv('dataframes/df_start_act_16.csv',index= False)\n",
    "#df_end_act_16.to_csv('dataframes/df_end_act_16.csv',index= False)\n",
    "#df_variants_level_16.to_csv('dataframes/df_variants_level_16.csv',index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_31():\n",
    "    #Level 31 \n",
    "    level_31 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:8])\n",
    "    level_31_df = pm.convert_to_dataframe(level_31)\n",
    "    level_31_heunet = pm.discover_heuristics_net(level_31)\n",
    "    pm.view_heuristics_net(level_31_heunet)\n",
    "\n",
    "    start_act_31 = pm.get_start_activities(level_31)\n",
    "    key_31 = []\n",
    "    value_31 = []\n",
    "    for k,v in start_act_31.items():\n",
    "        key_31.append(k)\n",
    "        value_31.append(v)\n",
    "    df_start_act_31 = pd.DataFrame({'Activity':key_31,'number_cases':value_31})\n",
    "    df_start_act_31.to_sql(name= 'df_start_act_31', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_31 = pm.get_end_activities(level_31)\n",
    "    key_31_e = []\n",
    "    value_31_e = []\n",
    "    for k,v in end_act_31.items():\n",
    "        key_31_e.append(k)\n",
    "        value_31_e.append(v)\n",
    "    df_end_act_31 = pd.DataFrame({'Activity':key_31_e,'number_cases':value_31_e})\n",
    "    df_end_act_31['Percentage'] = df_end_act_31['number_cases'] / len(level_31_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_31.to_sql(name= 'df_end_act_31', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_31 = plx.bar(data_frame=df_end_act_31,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_31\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_31 = pm.discover_bpmn_inductive(level_31)\n",
    "    pm.view_bpmn(bpmn_31)\n",
    "\n",
    "\n",
    "    df_variants_level_31 = variants.get_variants_df(level_31)\n",
    "    df_variants_level_31 =  df_variants_level_31[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_31['len_trace'] = [len(x) for x in df_variants_level_31['trace'].to_list() ]\n",
    "    df_variants_level_31.to_sql(name = 'df_variants_level_31', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "\n",
    "\n",
    "    len_variance_31 = plx.bar(df_variants_level_31,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_31\n",
    "    ocurrance_31 = plx.bar(df_variants_level_31,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_31\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_31, im_inductive_31, fm_inductive_31 = pm.discover_petri_net_inductive(level_31)\n",
    "    pm.view_petri_net(net_inductive_31, im_inductive_31, fm_inductive_31)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_31, im_alpha_31, fm_alpha_31 = pm.discover_petri_net_alpha(level_31)\n",
    "    pm.view_petri_net(net_alpha_31, im_alpha_31, fm_alpha_31)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_31, im_alphaplus_31, fm_alphaplus_31 = pm.discover_petri_net_alpha_plus(level_31)\n",
    "    pm.view_petri_net(net_alphaplus_31, im_alphaplus_31, fm_alphaplus_31 )\n",
    "\n",
    "\n",
    "#df_start_act_31 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_31\"\"\", con= engine)\n",
    "#df_end_act_31 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_31\"\"\", con= engine)\n",
    "#df_variants_level_31 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_31\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_31.to_csv('dataframes/df_start_act_31.csv',index= False)\n",
    "#df_end_act_31.to_csv('dataframes/df_end_act_31.csv',index= False)\n",
    "#df_variants_level_31.to_csv('dataframes/df_variants_level_31.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_46():\n",
    "    #Level 46 \n",
    "    level_46 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:12])\n",
    "    level_46_df = pm.convert_to_dataframe(level_46)\n",
    "    level_46_heunet = pm.discover_heuristics_net(level_46)\n",
    "    pm.view_heuristics_net(level_46_heunet)\n",
    "\n",
    "    start_act_46 = pm.get_start_activities(level_46)\n",
    "    key_46 = []\n",
    "    value_46 = []\n",
    "    for k,v in start_act_46.items():\n",
    "        key_46.append(k)\n",
    "        value_46.append(v)\n",
    "    df_start_act_46 = pd.DataFrame({'Activity':key_46,'number_cases':value_46})\n",
    "    df_start_act_46.to_sql(name= 'df_start_act_46', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_46 = pm.get_end_activities(level_46)\n",
    "    key_46_e = []\n",
    "    value_46_e = []\n",
    "    for k,v in end_act_46.items():\n",
    "        key_46_e.append(k)\n",
    "        value_46_e.append(v)\n",
    "    df_end_act_46 = pd.DataFrame({'Activity':key_46_e,'number_cases':value_46_e})\n",
    "    df_end_act_46['Percentage'] = df_end_act_46['number_cases'] / len(level_46_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_46.to_sql(name= 'df_end_act_46', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_46 = plx.bar(data_frame=df_end_act_46,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_46\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_46 = pm.discover_bpmn_inductive(level_46)\n",
    "    pm.view_bpmn(bpmn_46)\n",
    "\n",
    "\n",
    "    df_variants_level_46 = variants.get_variants_df(level_46)\n",
    "    df_variants_level_46 =  df_variants_level_46[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_46['len_trace'] = [len(x) for x in df_variants_level_46['trace'].to_list() ]\n",
    "    df_variants_level_46.to_sql(name = 'df_variants_level_46', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "\n",
    "\n",
    "    len_variance_46 = plx.bar(df_variants_level_46,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_46\n",
    "    ocurrance_46 = plx.bar(df_variants_level_46,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_46\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_46, im_inductive_46, fm_inductive_46 = pm.discover_petri_net_inductive(level_46)\n",
    "    pm.view_petri_net(net_inductive_46, im_inductive_46, fm_inductive_46)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_46, im_alpha_46, fm_alpha_46 = pm.discover_petri_net_alpha(level_46)\n",
    "    pm.view_petri_net(net_alpha_46, im_alpha_46, fm_alpha_46)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_46, im_alphaplus_46, fm_alphaplus_46 = pm.discover_petri_net_alpha_plus(level_46)\n",
    "    pm.view_petri_net(net_alphaplus_46, im_alphaplus_46, fm_alphaplus_46 )\n",
    "\n",
    "\n",
    "#df_start_act_46 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_46\"\"\", con= engine)\n",
    "#df_end_act_46 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_46\"\"\", con= engine)\n",
    "#df_variants_level_46 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_46\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_46.to_csv('dataframes/df_start_act_46.csv',index= False)\n",
    "#df_end_act_46.to_csv('dataframes/df_end_act_46.csv',index= False)\n",
    "#df_variants_level_46.to_csv('dataframes/df_variants_level_46.csv',index= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_46():\n",
    "    #Level 61 \n",
    "    level_61 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:60])\n",
    "    level_61_df = pm.convert_to_dataframe(level_61)\n",
    "    level_61_heunet = pm.discover_heuristics_net(level_61)\n",
    "    pm.view_heuristics_net(level_61_heunet)\n",
    "\n",
    "    start_act_61 = pm.get_start_activities(level_61)\n",
    "    key_61 = []\n",
    "    value_61 = []\n",
    "    for k,v in start_act_61.items():\n",
    "        key_61.append(k)\n",
    "        value_61.append(v)\n",
    "    df_start_act_61 = pd.DataFrame({'Activity':key_61,'number_cases':value_61})\n",
    "    df_start_act_61.to_sql(name= 'df_start_act_61', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_61 = pm.get_end_activities(level_61)\n",
    "    key_61_e = []\n",
    "    value_61_e = []\n",
    "    for k,v in end_act_61.items():\n",
    "        key_61_e.append(k)\n",
    "        value_61_e.append(v)\n",
    "    df_end_act_61 = pd.DataFrame({'Activity':key_61_e,'number_cases':value_61_e})\n",
    "    df_end_act_61['Percentage'] = df_end_act_61['number_cases'] / len(level_61_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_61.to_sql(name= 'df_end_act_61', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_61 = plx.bar(data_frame=df_end_act_61,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_61\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_61 = pm.discover_bpmn_inductive(level_61)\n",
    "    pm.view_bpmn(bpmn_61)\n",
    "\n",
    "\n",
    "    df_variants_level_61 = variants.get_variants_df(level_61)\n",
    "    df_variants_level_61 =  df_variants_level_61[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_61['len_trace'] = [len(x) for x in df_variants_level_61['trace'].to_list() ]\n",
    "    #df_variants_level_61.to_sql(name = 'df_variants_level_61', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "\n",
    "\n",
    "    len_variance_61 = plx.bar(df_variants_level_61,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_61\n",
    "    ocurrance_61 = plx.bar(df_variants_level_61,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_61\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_61, im_inductive_61, fm_inductive_61 = pm.discover_petri_net_inductive(level_61)\n",
    "    pm.view_petri_net(net_inductive_61, im_inductive_61, fm_inductive_61)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_61, im_alpha_61, fm_alpha_61 = pm.discover_petri_net_alpha(level_61)\n",
    "    pm.view_petri_net(net_alpha_61, im_alpha_61, fm_alpha_61)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_61, im_alphaplus_61, fm_alphaplus_61 = pm.discover_petri_net_alpha_plus(level_61)\n",
    "    pm.view_petri_net(net_alphaplus_61, im_alphaplus_61, fm_alphaplus_61 )\n",
    "\n",
    "\n",
    "#df_start_act_61 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_61\"\"\", con= engine)\n",
    "#df_end_act_61 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_61\"\"\", con= engine)\n",
    "#df_variants_level_61 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_61\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_61.to_csv('dataframes/df_start_act_61.csv',index= False)\n",
    "#df_end_act_61.to_csv('dataframes/df_end_act_61.csv',index= False)\n",
    "#df_variants_level_61.to_csv('dataframes/df_variants_level_61.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_76():\n",
    "    #Level 76 \n",
    "    level_76 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:120])\n",
    "    level_76_df = pm.convert_to_dataframe(level_76)\n",
    "    level_76_heunet = pm.discover_heuristics_net(level_76)\n",
    "    pm.view_heuristics_net(level_76_heunet)\n",
    "\n",
    "    start_act_76 = pm.get_start_activities(level_76)\n",
    "    key_76 = []\n",
    "    value_76 = []\n",
    "    for k,v in start_act_76.items():\n",
    "        key_76.append(k)\n",
    "        value_76.append(v)\n",
    "    df_start_act_76 = pd.DataFrame({'Activity':key_76,'number_cases':value_76})\n",
    "    df_start_act_76.to_sql(name= 'df_start_act_76', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_76 = pm.get_end_activities(level_76)\n",
    "    key_76_e = []\n",
    "    value_76_e = []\n",
    "    for k,v in end_act_76.items():\n",
    "        key_76_e.append(k)\n",
    "        value_76_e.append(v)\n",
    "    df_end_act_76 = pd.DataFrame({'Activity':key_76_e,'number_cases':value_76_e})\n",
    "    df_end_act_76['Percentage'] = df_end_act_76['number_cases'] / len(level_76_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_76.to_sql(name= 'df_end_act_76', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_76 = plx.bar(data_frame=df_end_act_76,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_76\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_76 = pm.discover_bpmn_inductive(level_76)\n",
    "    pm.view_bpmn(bpmn_76)\n",
    "\n",
    "\n",
    "    df_variants_level_76 = variants.get_variants_df(level_76)\n",
    "    df_variants_level_76 =  df_variants_level_76[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_76['len_trace'] = [len(x) for x in df_variants_level_76['trace'].to_list() ]\n",
    "    df_variants_level_76.to_sql(name = 'df_variants_level_76', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "\n",
    "\n",
    "    len_variance_76 = plx.bar(df_variants_level_76,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_76\n",
    "    ocurrance_76 = plx.bar(df_variants_level_76,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_76\n",
    "\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_76, im_inductive_76, fm_inductive_76 = pm.discover_petri_net_inductive(level_76)\n",
    "    pm.view_petri_net(net_inductive_76, im_inductive_76, fm_inductive_76)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_76, im_alpha_76, fm_alpha_76 = pm.discover_petri_net_alpha(level_76)\n",
    "    pm.view_petri_net(net_alpha_76, im_alpha_76, fm_alpha_76)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_76, im_alphaplus_76, fm_alphaplus_76 = pm.discover_petri_net_alpha_plus(level_76)\n",
    "    pm.view_petri_net(net_alphaplus_76, im_alphaplus_76, fm_alphaplus_76 )\n",
    "\n",
    "\n",
    "#df_start_act_76 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_76\"\"\", con= engine)\n",
    "#df_end_act_76 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_76\"\"\", con= engine)\n",
    "#df_variants_level_76 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_76\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_76.to_csv('dataframes/df_start_act_76.csv',index= False)\n",
    "#df_end_act_76.to_csv('dataframes/df_end_act_76.csv',index= False)\n",
    "#df_variants_level_76.to_csv('dataframes/df_variants_level_76.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_91():\n",
    "\n",
    "    level_91 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:650])\n",
    "    level_91_df = pm.convert_to_dataframe(level_91)\n",
    "    level_91_heunet = pm.discover_heuristics_net(level_91)\n",
    "    pm.view_heuristics_net(level_91_heunet)\n",
    "\n",
    "    start_act_91 = pm.get_start_activities(level_91)\n",
    "    key_91 = []\n",
    "    value_91 = []\n",
    "    for k,v in start_act_91.items():\n",
    "        key_91.append(k)\n",
    "        value_91.append(v)\n",
    "    df_start_act_91 = pd.DataFrame({'Activity':key_91,'number_cases':value_91})\n",
    "    df_start_act_91.to_sql(name= 'df_start_act_91', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_91 = pm.get_end_activities(level_91)\n",
    "    key_91_e = []\n",
    "    value_91_e = []\n",
    "    for k,v in end_act_91.items():\n",
    "        key_91_e.append(k)\n",
    "        value_91_e.append(v)\n",
    "    df_end_act_91 = pd.DataFrame({'Activity':key_91_e,'number_cases':value_91_e})\n",
    "    df_end_act_91['Percentage'] = df_end_act_91['number_cases'] / len(level_91_df['case:concept:name'].unique()) * 100 \n",
    "    df_end_act_91.to_sql(name= 'df_end_act_91', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_91 = plx.bar(data_frame=df_end_act_91,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_91\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_91 = pm.discover_bpmn_inductive(level_91)\n",
    "    pm.view_bpmn(bpmn_91)\n",
    "\n",
    "\n",
    "    df_variants_level_91 = variants.get_variants_df(level_91)\n",
    "    df_variants_level_91 =  df_variants_level_91[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_91['len_trace'] = [len(x) for x in df_variants_level_91['trace'].to_list() ]\n",
    "    df_variants_level_91.to_sql(name = 'df_variants_level_91', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "    len_variance_91 = plx.bar(df_variants_level_91,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_91\n",
    "    ocurrance_91 = plx.bar(df_variants_level_91,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_91\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_91, im_inductive_91, fm_inductive_91 = pm.discover_petri_net_inductive(level_91)\n",
    "    pm.view_petri_net(net_inductive_91, im_inductive_91, fm_inductive_91)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_91, im_alpha_91, fm_alpha_91 = pm.discover_petri_net_alpha(level_91)\n",
    "    pm.view_petri_net(net_alpha_91, im_alpha_91, fm_alpha_91)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_91, im_alphaplus_91, fm_alphaplus_91 = pm.discover_petri_net_alpha_plus(level_91)\n",
    "    pm.view_petri_net(net_alphaplus_91, im_alphaplus_91, fm_alphaplus_91 )\n",
    "\n",
    "\n",
    "#df_start_act_91 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_91\"\"\", con= engine)\n",
    "#df_end_act_91 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_91\"\"\", con= engine)\n",
    "#df_variants_level_91 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_91\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_91.to_csv('dataframes/df_start_act_91.csv',index= False)\n",
    "#df_end_act_91.to_csv('dataframes/df_end_act_91.csv',index= False)\n",
    "#df_variants_level_91.to_csv('dataframes/df_variants_level_91.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_level_91():\n",
    "    level_100 = pm.filter_variants(event_log,df_variants['trace'].to_list())\n",
    "    level_100_df = pm.convert_to_dataframe(level_100)\n",
    "    level_100_heunet = pm.discover_heuristics_net(level_100)\n",
    "    pm.view_heuristics_net(level_100_heunet)\n",
    "\n",
    "    start_act_100 = pm.get_start_activities(level_100)\n",
    "    key_100 = []\n",
    "    value_100 = []\n",
    "    for k,v in start_act_100.items():\n",
    "        key_100.append(k)\n",
    "        value_100.append(v)\n",
    "    df_start_act_100 = pd.DataFrame({'Activity':key_100,'number_cases':value_100})\n",
    "    #df_start_act_100.to_sql(name= 'df_start_act_100', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "\n",
    "    end_act_100 = pm.get_end_activities(level_100)\n",
    "    key_100_e = []\n",
    "    value_100_e = []\n",
    "    for k,v in end_act_100.items():\n",
    "        key_100_e.append(k)\n",
    "        value_100_e.append(v)\n",
    "    df_end_act_100 = pd.DataFrame({'Activity':key_100_e,'number_cases':value_100_e})\n",
    "    df_end_act_100['Percentage'] = df_end_act_100['number_cases'] / len(level_100_df['case:concept:name'].unique()) * 100 \n",
    "    #df_end_act_100.to_sql(name= 'df_end_act_100', schema = 'billing',con= engine,index =False,if_exists='replace')\n",
    "\n",
    "    #% Ending Activities\n",
    "    plot_ends_100 = plx.bar(data_frame=df_end_act_100,y = 'Activity',x = 'Percentage')\n",
    "    plot_ends_100\n",
    "\n",
    "    #Business Process Model\n",
    "    bpmn_100 = pm.discover_bpmn_inductive(level_100)\n",
    "    pm.view_bpmn(bpmn_100)\n",
    "\n",
    "\n",
    "    df_variants_level_100 = variants.get_variants_df(level_100)\n",
    "    df_variants_level_100 =  df_variants_level_100[['trace','len','percentage','Variant_Name']]\n",
    "    df_variants_level_100['len_trace'] = [len(x) for x in df_variants_level_100['trace'].to_list() ]\n",
    "    df_variants_level_100.to_sql(name = 'df_variants_level_100', schema = 'billing',con = engine, if_exists='replace',index = False)\n",
    "\n",
    "    len_variance_100 = plx.bar(df_variants_level_100,x = 'Variant_Name', y = 'len_trace' )\n",
    "    len_variance_100\n",
    "    ocurrance_100 = plx.bar(df_variants_level_100,x = 'Variant_Name', y = 'percentage')\n",
    "    ocurrance_100\n",
    "\n",
    "    #Petri Net Inductive\n",
    "    net_inductive_100, im_inductive_100, fm_inductive_100 = pm.discover_petri_net_inductive(level_100)\n",
    "    pm.view_petri_net(net_inductive_100, im_inductive_100, fm_inductive_100)\n",
    "    # Petri Net alpha\n",
    "    net_alpha_100, im_alpha_100, fm_alpha_100 = pm.discover_petri_net_alpha(level_100)\n",
    "    pm.view_petri_net(net_alpha_100, im_alpha_100, fm_alpha_100)\n",
    "    #Petrinet alpha plus\n",
    "    net_alphaplus_100, im_alphaplus_100, fm_alphaplus_100 = pm.discover_petri_net_alpha_plus(level_100)\n",
    "    pm.view_petri_net(net_alphaplus_100, im_alphaplus_100, fm_alphaplus_100 )\n",
    "\n",
    "\n",
    "\n",
    "#df_start_act_100 = pd.read_sql(\"\"\"SELECT * FROM billing.df_start_act_100\"\"\", con= engine)\n",
    "#df_end_act_100 = pd.read_sql(\"\"\"SELECT * FROM billing.df_end_act_100\"\"\", con= engine)\n",
    "#df_variants_level_100 = pd.read_sql(\"\"\"SELECT * FROM billing.df_variants_level_100\"\"\", con= engine)\n",
    "\n",
    "#df_start_act_100.to_csv('dataframes/df_start_act_100.csv',index= False)\n",
    "#df_end_act_100.to_csv('dataframes/df_end_act_100.csv',index= False)\n",
    "#df_variants_level_100.to_csv('dataframes/df_variants_level_100.csv',index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level_1 = pm.filter_variants(event_log,[df_variants['trace'].to_list()[0]])\n",
    "level_16 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:4])\n",
    "level_31 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:8])\n",
    "level_46 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:12])\n",
    "level_61 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:60])\n",
    "level_76 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:120])\n",
    "level_91 = pm.filter_variants(event_log,df_variants['trace'].to_list()[0:650])\n",
    "level_100 = pm.filter_variants(event_log,df_variants['trace'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from tkinter import Label\n",
    "\n",
    "\n",
    "groups = [level_1,level_16,level_31,level_46,level_61,level_76,level_91,level_100 ]\n",
    "labels = ['_1','_16','_31','_46','_61','_76','_91','_100']\n",
    "\n",
    "\n",
    "for group, label_ in zip(groups,labels):\n",
    "    net, start, end = pm.discover_performance_dfg(group)\n",
    "    pm.save_vis_performance_dfg(dfg =net,start_activities=start,end_activities=end,file_path='images/timing/DFG'+label_+'.png',bgcolor=\"white\")\n",
    "    print('saved' + label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time = event_log_df['time:timestamp'].min()\n",
    "max_time = event_log_df['time:timestamp'].max()\n",
    "\n",
    "days = (max_time-min_time).days\n",
    "_seconds = (max_time-min_time).seconds\n",
    "hours =  int(_seconds/3600)\n",
    "_minutes = (_seconds/3600) - hours\n",
    "minutes = int(_minutes * 60)\n",
    "\n",
    "time_head_ = pd.DataFrame({'min_time':[min_time],'max_time':[max_time],'days':[days],'hours':[hours],'minutes':[minutes]})\n",
    "#time_head_.to_sql(name = 'time_head',schema='billing',con=engine,if_exists='replace',index=False)\n",
    "#time_head_.to_csv('dataframes/time_head.csv')\n",
    "#time_head_ = pd.read_sql(\"\"\"SELECT * FROM billing.time_head\"\"\",con= engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases_df_list =event_log_df['case:concept:name'].drop_duplicates().to_frame().reset_index().drop('index',axis =1)\n",
    "cases_df_list.to_sql(name = \"cases_df_list\",schema=\"billing\",if_exists=\"replace\",index =False, con  = engine)\n",
    "cases_df_list.to_csv('dataframes/cases_df_list.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_dfs = []\n",
    "\n",
    "for case in cases_df_list['case:concept:name']:\n",
    "    frame = event_log_df[event_log_df['case:concept:name'] == case][['time:timestamp','concept:name','case:concept:name']]\n",
    "    interval = frame['time:timestamp'].diff().shift(-1).fillna(datetime.timedelta(0)).apply(lambda y : y.total_seconds()/3600)\n",
    "    frame['interval'] = interval\n",
    "    cases_dfs.append(frame)\n",
    "    print(frame['case:concept:name'].drop_duplicates().to_list()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isCancelled</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>caseType</th>\n",
       "      <th>speciality</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>blocked</th>\n",
       "      <th>isClosed</th>\n",
       "      <th>flagD</th>\n",
       "      <th>...</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>closeCode</th>\n",
       "      <th>actRed</th>\n",
       "      <th>actOrange</th>\n",
       "      <th>flagC</th>\n",
       "      <th>msgCount</th>\n",
       "      <th>version</th>\n",
       "      <th>msgType</th>\n",
       "      <th>msgCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>2012-12-16 18:33:10+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>ResA</td>\n",
       "      <td>NEW</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-15 18:00:37+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-16 02:53:38+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RELEASE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-17 11:56:29+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CODE OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-19 02:44:31+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResB</td>\n",
       "      <td>BILLED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451354</th>\n",
       "      <td>False</td>\n",
       "      <td>OM</td>\n",
       "      <td>2015-12-13 18:31:23+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>ResA</td>\n",
       "      <td>NEW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>AXQE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451355</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-14 20:17:47+00:00</td>\n",
       "      <td>B</td>\n",
       "      <td>L</td>\n",
       "      <td>ResDJ</td>\n",
       "      <td>NEW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>BXQE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451356</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-14 21:00:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ResFR</td>\n",
       "      <td>DELETE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>BXQE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451357</th>\n",
       "      <td>False</td>\n",
       "      <td>LL</td>\n",
       "      <td>2016-01-11 18:40:47+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>ResA</td>\n",
       "      <td>NEW</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>CXQE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451358</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-13 21:48:13+00:00</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>ResJA</td>\n",
       "      <td>NEW</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>complete</td>\n",
       "      <td>DXQE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451359 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       isCancelled diagnosis            time:timestamp caseType speciality  \\\n",
       "0            False         A 2012-12-16 18:33:10+00:00        A          A   \n",
       "1              NaN       NaN 2013-12-15 18:00:37+00:00      NaN        NaN   \n",
       "2              NaN       NaN 2013-12-16 02:53:38+00:00      NaN        NaN   \n",
       "3              NaN       NaN 2013-12-17 11:56:29+00:00      NaN        NaN   \n",
       "4              NaN       NaN 2013-12-19 02:44:31+00:00      NaN        NaN   \n",
       "...            ...       ...                       ...      ...        ...   \n",
       "451354       False        OM 2015-12-13 18:31:23+00:00        A          E   \n",
       "451355       False       NaN 2016-01-14 20:17:47+00:00        B          L   \n",
       "451356        True       NaN 2016-01-14 21:00:13+00:00      NaN        NaN   \n",
       "451357       False        LL 2016-01-11 18:40:47+00:00        A          D   \n",
       "451358       False       NaN 2016-01-13 21:48:13+00:00        I          K   \n",
       "\n",
       "       org:resource concept:name blocked isClosed  flagD  ...  \\\n",
       "0              ResA          NEW   False     True   True  ...   \n",
       "1               NaN          FIN     NaN      NaN    NaN  ...   \n",
       "2               NaN      RELEASE     NaN      NaN    NaN  ...   \n",
       "3               NaN      CODE OK     NaN      NaN    NaN  ...   \n",
       "4              ResB       BILLED     NaN      NaN    NaN  ...   \n",
       "...             ...          ...     ...      ...    ...  ...   \n",
       "451354         ResA          NEW   False    False  False  ...   \n",
       "451355        ResDJ          NEW   False    False  False  ...   \n",
       "451356        ResFR       DELETE     NaN      NaN    NaN  ...   \n",
       "451357         ResA          NEW   False    False  False  ...   \n",
       "451358        ResJA          NEW   False     True  False  ...   \n",
       "\n",
       "       lifecycle:transition case:concept:name closeCode actRed actOrange  \\\n",
       "0                  complete                 A       NaN    NaN       NaN   \n",
       "1                  complete                 A         A    NaN       NaN   \n",
       "2                  complete                 A       NaN    NaN       NaN   \n",
       "3                  complete                 A       NaN  False     False   \n",
       "4                  complete                 A       NaN    NaN       NaN   \n",
       "...                     ...               ...       ...    ...       ...   \n",
       "451354             complete              AXQE       NaN    NaN       NaN   \n",
       "451355             complete              BXQE       NaN    NaN       NaN   \n",
       "451356             complete              BXQE       NaN    NaN       NaN   \n",
       "451357             complete              CXQE       NaN    NaN       NaN   \n",
       "451358             complete              DXQE       NaN    NaN       NaN   \n",
       "\n",
       "        flagC msgCount version msgType  msgCode  \n",
       "0         NaN      NaN     NaN     NaN      NaN  \n",
       "1         NaN      NaN     NaN     NaN      NaN  \n",
       "2         NaN      NaN     NaN     NaN      NaN  \n",
       "3       False      0.0       A     NaN      NaN  \n",
       "4         NaN      NaN     NaN     NaN      NaN  \n",
       "...       ...      ...     ...     ...      ...  \n",
       "451354    NaN      NaN     NaN     NaN      NaN  \n",
       "451355    NaN      NaN     NaN     NaN      NaN  \n",
       "451356    NaN      NaN     NaN     NaN      NaN  \n",
       "451357    NaN      NaN     NaN     NaN      NaN  \n",
       "451358    NaN      NaN     NaN     NaN      NaN  \n",
       "\n",
       "[451359 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_df = pd.concat(cases_dfs)\n",
    "#cases_df.to_sql(con = engine, schema=\"billing\",index = False,name=\"cases_df\", if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log_df.head(150).to_csv(\"dataframes/sample_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\" SELECT \n",
    "\t\"concept:name\",\n",
    "\tMIN(\"interval\") AS min,\n",
    "\tMAX(\"interval\") AS max,\n",
    "\tAVG(\"interval\") AS mean,\n",
    "\tSTDDEV(\"interval\") AS std,\n",
    "\tPERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY \"interval\") AS q1,\n",
    "\tPERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY \"interval\") AS q3\n",
    "FROM \n",
    "\tbilling.full_case_variant_time \n",
    "WHERE \"Variant\" IN ('Variant_947') \n",
    "GROUP BY \"concept:name\" \"\"\"\n",
    "\n",
    "\n",
    "xc = pd.read_sql(con = engine, sql = sql )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\AlejandroVelez\\OneDrive - Accelirate, Inc\\Documents\\Accelirate\\Hospital billing process\\back_process.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AlejandroVelez/OneDrive%20-%20Accelirate%2C%20Inc/Documents/Accelirate/Hospital%20billing%20process/back_process.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pyautogui\u001b[39m.\u001b[39mtypewrite(\u001b[39mstr\u001b[39m(i))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/AlejandroVelez/OneDrive%20-%20Accelirate%2C%20Inc/Documents/Accelirate/Hospital%20billing%20process/back_process.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pyautogui\u001b[39m.\u001b[39mpress(\u001b[39m\"\u001b[39m\u001b[39menter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/AlejandroVelez/OneDrive%20-%20Accelirate%2C%20Inc/Documents/Accelirate/Hospital%20billing%20process/back_process.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "for i in np.arange(0,15000):\n",
    "    pyautogui.typewrite(str(i))\n",
    "    pyautogui.press(\"enter\")\n",
    "    time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dff8faf8e781f6ea0a1aed9b741f4b9fc26288b9f855760d8b1af9082cb4a564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
